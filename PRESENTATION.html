<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Intelligent Multi-Agent NER System</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            overflow: hidden;
            height: 100vh;
        }

        .presentation {
            width: 100vw;
            height: 100vh;
            position: relative;
        }

        .slide {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: none;
            padding: 3rem 5rem;
            background: white;
            overflow-y: auto;
        }

        .slide.active {
            display: flex;
            flex-direction: column;
            animation: slideIn 0.5s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateX(50px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        .slide-number {
            position: absolute;
            bottom: 2rem;
            right: 3rem;
            font-size: 0.9rem;
            color: #666;
            font-weight: 500;
        }

        h1 {
            color: #667eea;
            font-size: 2.5rem;
            margin-bottom: 1.5rem;
            border-bottom: 3px solid #667eea;
            padding-bottom: 0.5rem;
        }

        h2 {
            color: #764ba2;
            font-size: 2rem;
            margin-bottom: 1rem;
        }

        h3 {
            color: #667eea;
            font-size: 1.5rem;
            margin-top: 1rem;
            margin-bottom: 0.7rem;
        }

        p, li {
            font-size: 1.1rem;
            line-height: 1.6;
            color: #333;
            margin-bottom: 0.8rem;
        }

        ul {
            margin-left: 2rem;
            margin-bottom: 1rem;
        }

        .title-slide {
            justify-content: center;
            align-items: center;
            text-align: center;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .title-slide h1 {
            color: white;
            font-size: 3rem;
            border: none;
            margin-bottom: 2rem;
        }

        .title-slide p {
            color: white;
            font-size: 1.3rem;
            margin: 0.5rem 0;
        }

        .subtitle {
            font-size: 1.2rem;
            color: #555;
            margin-bottom: 1rem;
            font-style: italic;
        }

        .highlight {
            background: #fff3cd;
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-weight: 600;
        }

        .box {
            background: #f8f9fa;
            border-left: 4px solid #667eea;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 4px;
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin: 1rem 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 0.6rem;
            text-align: left;
        }

        th {
            background-color: #667eea;
            color: white;
            font-weight: 600;
        }

        tr:nth-child(even) {
            background-color: #f8f9fa;
        }

        .reference {
            font-size: 0.85rem;
            line-height: 1.4;
            margin-bottom: 0.5rem;
        }

        strong {
            color: #764ba2;
        }

        .agent-box {
            background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
            padding: 0.8rem;
            margin: 0.5rem 0;
            border-radius: 8px;
            border: 2px solid #667eea;
        }

        .metric {
            display: inline-block;
            background: #28a745;
            color: white;
            padding: 0.3rem 0.8rem;
            border-radius: 20px;
            font-weight: 600;
            margin: 0.2rem;
        }
    </style>
</head>
<body>
    <div class="presentation">
        <!-- Slide 1: Title -->
        <div class="slide active title-slide">
            <h1>Intelligent Multi-Agent Named Entity Recognition System</h1>
            <h2 style="color: white; border: none;">Using LLM Orchestration and Azure OpenAI</h2>
            <p style="margin-top: 3rem;">Divyanshi Joshi </p>
            <p style="margin-top: 1.5rem; font-size: 1rem;">Maharaja Agrasen Institute of Technology</p>
            <p style="font-size: 1rem;">November 2025</p>
            <div class="slide-number">1 / 20</div>
        </div>

        <!-- Slide 2: Abstract -->
        <div class="slide">
            <h1>Abstract</h1>
            <p class="subtitle">Collaborative Processing Architecture for Entity Recognition (CPA-ER)</p>
            <p>A novel, multi-agent framework designed to achieve robust, high-confidence <strong>Zero-Shot Named Entity Recognition (ZNER)</strong> without reliance on extensive, manually labeled domain-specific training data.</p>
            
            <div class="box">
                <h3>Key Problem</h3>
                <p>Traditional supervised NER models suffer critical performance degradation in resource-constrained or evolving domains (clinical, financial documents).</p>
            </div>

            <h3>Major Limitations Addressed:</h3>
            <ul>
                <li><strong>Contextual Feature Blindness:</strong> Models overlook crucial contextual signals</li>
                <li><strong>Flawed In-Context Learning:</strong> Poor quality demonstration selection</li>
            </ul>

            <h3>Implementation:</h3>
            <p>Four specialized, sequential agents powered by <span class="highlight">Azure OpenAI models</span> orchestrated via <span class="highlight">LangGraph</span></p>
            <div class="slide-number">2 / 20</div>
        </div>

        <!-- Slide 3: Introduction - Evolution of NER -->
        <div class="slide">
            <h1>Evolution of Named Entity Recognition</h1>
            
            <h3>What is NER?</h3>
            <p>Automatically locating and classifying key informational components in unstructured text: persons, organizations, locations, temporal expressions, monetary values.</p>

            <h3>Three Eras of NER:</h3>
            
            <div class="agent-box">
                <strong>1. Early Systems (Rule-Based & Lexicon-Driven)</strong>
                <p>Handcrafted grammar rules, predefined gazetteers. Precise but brittle, poor generalization.</p>
            </div>

            <div class="agent-box">
                <strong>2. Statistical Models (Late 1990s-2000s)</strong>
                <p>Conditional Random Fields (CRF), feature engineering. Systems like StanfordCoreNLP achieved significant improvements.</p>
            </div>

            <div class="agent-box">
                <strong>3. Deep Learning & Transformers (Current)</strong>
                <p>BERT, RoBERTa variants using self-attention mechanisms. Achieving 90%+ F1-score on benchmarks like CoNLL-2003.</p>
            </div>

            <p style="margin-top: 1rem;"><em>Origin: Message Understanding Conference (MUC) 1996</em></p>
            <div class="slide-number">3 / 20</div>
        </div>

        <!-- Slide 4: Zero-Shot NER Challenge -->
        <div class="slide">
            <h1>The Critical Challenge of Zero-Shot NER</h1>
            
            <div class="box">
                <h3>The Problem</h3>
                <p>Current deep learning models require <strong>extensive, manually labeled data</strong> that is often unavailable in specialized domains:</p>
                <ul style="margin-top: 0.5rem;">
                    <li>Clinical notes</li>
                    <li>Proprietary financial documents</li>
                    <li>Legal contracts</li>
                    <li>Emerging scientific literature</li>
                </ul>
            </div>

            <h3>Zero-Shot NER Solution</h3>
            <p>Identify and classify entities using only <strong>generalized knowledge</strong> and a <strong>list of target entity types</strong>, without prior fine-tuning on domain-specific examples.</p>

            <h3>Two Critical Failure Points Identified:</h3>
            
            <div class="two-column">
                <div>
                    <div class="agent-box">
                        <strong>Failure Point 1:</strong><br>
                        <strong>Contextual Feature Blindness</strong>
                        <p style="font-size: 0.95rem;">Models overlook contextual signals, leading to misclassification. Example: "Apple" could be fruit, company, or record label.</p>
                    </div>
                </div>
                <div>
                    <div class="agent-box">
                        <strong>Failure Point 2:</strong><br>
                        <strong>Flawed In-Context Learning</strong>
                        <p style="font-size: 0.95rem;">Indiscriminate demonstration selection based on shallow similarity compromises reliability.</p>
                    </div>
                </div>
            </div>
            <div class="slide-number">4 / 20</div>
        </div>

        <!-- Slide 5: Literature Survey Overview -->
        <div class="slide">
            <h1>Literature Survey: Existing Approaches</h1>
            
            <p class="subtitle">Analysis of five established NER methodologies</p>

            <table>
                <tr>
                    <th>System</th>
                    <th>Type</th>
                    <th>Key Technology</th>
                    <th>Primary Limitation</th>
                </tr>
                <tr>
                    <td><strong>spaCy</strong></td>
                    <td>Supervised</td>
                    <td>CNN + Bloom embeddings</td>
                    <td>Requires extensive retraining</td>
                </tr>
                <tr>
                    <td><strong>Hugging Face</strong></td>
                    <td>Supervised</td>
                    <td>Transformer models</td>
                    <td>No self-correction mechanism</td>
                </tr>
                <tr>
                    <td><strong>GLiNER</strong></td>
                    <td>Zero-Shot</td>
                    <td>Span-prompt matching</td>
                    <td>Contextual feature blindness</td>
                </tr>
                <tr>
                    <td><strong>Presidio</strong></td>
                    <td>Hybrid PII</td>
                    <td>Rules + NER</td>
                    <td>PII-specific, no semantic classification</td>
                </tr>
                <tr>
                    <td><strong>Scrubadub</strong></td>
                    <td>Rule-based</td>
                    <td>Pattern matching</td>
                    <td>Anonymization only, no classification</td>
                </tr>
            </table>

            <div class="box" style="margin-top: 1.5rem;">
                <strong>Critical Gap Identified:</strong> No existing system combines explicit contextual feature engineering with quality-controlled in-context learning for robust zero-shot extraction.
            </div>
            <div class="slide-number">5 / 20</div>
        </div>

        <!-- Slide 6: spaCy Analysis -->
        <div class="slide">
            <h1>Baseline Analysis: spaCy</h1>
            
            <h3>Overview</h3>
            <p>Industrial-strength NLP library valued for speed and production readiness.</p>

            <h3>Architecture</h3>
            <ul>
                <li>Deep Convolutional Neural Network (CNN) with residual connections</li>
                <li>Bloom embeddings (memory-efficient hash-based)</li>
                <li>Subword feature extraction</li>
                <li>Comprehensive linguistic annotations</li>
            </ul>

            <div class="box">
                <h3>Limitations for Zero-Shot Research</h3>
                <ul style="margin-top: 0.5rem;">
                    <li><strong>Fixed taxonomy:</strong> Requires complete retraining for new entity types</li>
                    <li><strong>Training data dependency:</strong> Needs 1000+ annotated examples</li>
                    <li><strong>No contextual reasoning:</strong> Limited to learned patterns</li>
                    <li><strong>Poor domain adaptation:</strong> Performance drops significantly on specialized domains</li>
                    <li><strong>Rigid entity classification:</strong> Cannot handle custom entity types without extensive model retraining</li>
                </ul>
            </div>

            <p><strong>Verdict:</strong> Excellent for supervised tasks, unsuitable for zero-shot scenarios.</p>
            <div class="slide-number">6 / 20</div>
        </div>

        <!-- Slide 7: Hugging Face Transformers -->
        <div class="slide">
            <h1>Baseline Analysis: Hugging Face Transformers</h1>
            
            <h3>Overview</h3>
            <p>Comprehensive ecosystem for state-of-the-art transformer models (BERT, RoBERTa, XLM-RoBERTa) for token classification.</p>

            <h3>Architecture Strengths</h3>
            <ul>
                <li>Self-attention mechanisms capture long-range dependencies</li>
                <li>High accuracy on benchmark datasets (90%+ F1-score)</li>
                <li>Pre-trained on massive corpora</li>
            </ul>

            <div class="box">
                <h3>Critical Drawbacks for Zero-Shot</h3>
                <ul style="margin-top: 0.5rem;">
                    <li><strong>Monolithic single-pass architecture:</strong> No iterative refinement</li>
                    <li><strong>Lack of reflexivity:</strong> Cannot evaluate uncertainty or self-correct</li>
                    <li><strong>Prohibitive computational cost:</strong> 355M+ parameters, CPU-intensive</li>
                    <li><strong>Domain shift vulnerability:</strong> Significant degradation on unseen domains</li>
                    <li><strong>Training requirement:</strong> Needs 500-5000 labeled examples</li>
                </ul>
            </div>

            <p><strong>Verdict:</strong> State-of-the-art for supervised NER, but lacks zero-shot adaptability and self-correction mechanisms.</p>
            <div class="slide-number">7 / 20</div>
        </div>

        <!-- Slide 8: GLiNER -->
        <div class="slide">
            <h1>Baseline Analysis: GLiNER</h1>
            
            <h3>Overview</h3>
            <p>Generalist and Lightweight model specifically designed for Zero-Shot NER. Reframes entity extraction as span-prompt matching in shared latent space.</p>

            <h3>Innovation</h3>
            <p>Encoder-only architecture that matches text spans to entity type prompts without fine-tuning.</p>

            <div class="box">
                <h3>Critical Limitations</h3>
                <ul style="margin-top: 0.5rem;">
                    <li><strong>Contextual Feature Blindness:</strong> No mechanism to explicitly identify Type-Related Features (TRFs)</li>
                    <li><strong>Indiscriminate Demonstration Use:</strong> Uses retrieved examples without quality assessment</li>
                    <li><strong>Limited Reasoning Depth:</strong> Encoder-only model cannot perform multi-step reasoning</li>
                    <li><strong>Context Window Constraints:</strong> Limited to ~512 tokens, requires chunking for long documents</li>
                    <li><strong>Performance Ceiling:</strong> Achieves only 70-80% accuracy on zero-shot tasks</li>
                </ul>
            </div>

            <p><strong>Verdict:</strong> Best existing zero-shot approach, but fundamental architectural limitations prevent production-grade performance.</p>
            <div class="slide-number">8 / 20</div>
        </div>

        <!-- Slide 9: Presidio & Scrubadub -->
        <div class="slide">
            <h1>Baseline Analysis: Presidio & Scrubadub</h1>
            
            <div class="two-column">
                <div>
                    <h3>Presidio (Microsoft)</h3>
                    <p><strong>Type:</strong> Hybrid PII Detection</p>
                    <p><strong>Approach:</strong> Combines NER with rule-based recognizers, regex, and validation algorithms</p>
                    
                    <div class="box">
                        <strong>Limitations:</strong>
                        <ul style="font-size: 0.95rem; margin-top: 0.5rem;">
                            <li>PII-specific bias</li>
                            <li>Structural rigidity</li>
                            <li>No semantic classification</li>
                            <li>High maintenance overhead</li>
                            <li>Zero adaptability to custom entities</li>
                        </ul>
                    </div>
                </div>

                <div>
                    <h3>Scrubadub</h3>
                    <p><strong>Type:</strong> Pure Rule-Based Sanitization</p>
                    <p><strong>Approach:</strong> Pattern matching with "cleaners" for PII anonymization</p>
                    
                    <div class="box">
                        <strong>Critical Limitations:</strong>
                        <ul style="font-size: 0.95rem; margin-top: 0.5rem;">
                            <li>Anonymization-only goal</li>
                            <li>Zero semantic classification</li>
                            <li>No confidence scores</li>
                            <li>Completely unsuitable for research</li>
                        </ul>
                    </div>
                </div>
            </div>

            <p style="margin-top: 1rem;"><strong>Verdict:</strong> Both systems serve narrow anonymization purposes but lack the flexibility and semantic understanding required for general-purpose zero-shot NER.</p>
            <div class="slide-number">9 / 20</div>
        </div>

        <!-- Slide 10: Research Gap -->
        <div class="slide">
            <h1>Research Gap Identification</h1>
            
            <div class="box" style="background: #fff3cd; border-color: #ffc107;">
                <h3 style="color: #856404;">Critical Gap in ZNER Literature</h3>
                <p style="color: #856404;">Existing systems fail to meet requirements for robust, high-confidence zero-shot extraction</p>
            </div>

            <h3>Four Fundamental Deficiencies:</h3>

            <div class="agent-box">
                <strong>1. Lack of Explicit Contextual Feature Engineering</strong>
                <p>Models treat features as black boxes, missing domain-specific signals essential for disambiguation.</p>
            </div>

            <div class="agent-box">
                <strong>2. Poor Demonstration Quality Control</strong>
                <p>No mechanism to filter misleading examples in in-context learning, leading to performance degradation.</p>
            </div>

            <div class="agent-box">
                <strong>3. Insufficient Self-Consistency Mechanisms</strong>
                <p>Single-pass predictions are prone to hallucination and lack verification.</p>
            </div>

            <div class="agent-box">
                <strong>4. Limited Domain Adaptability</strong>
                <p>Cannot leverage unlabeled corpus for domain-specific tuning without retraining.</p>
            </div>

            <div class="slide-number">10 / 20</div>
        </div>

        <!-- Slide 11: Proposed Solution - CPA-ER -->
        <div class="slide">
            <h1>Proposed Solution: CPA-ER</h1>
            <h2>Collaborative Processing Architecture for Entity Recognition</h2>
            
            <p class="subtitle">A novel multi-agent framework addressing fundamental ZNER limitations</p>

            <h3>Core Architectural Principles:</h3>

            <div class="agent-box">
                <strong>1. Specialization</strong>
                <p>Each agent performs a specific, well-defined function, enabling optimized performance on that subtask.</p>
            </div>

            <div class="agent-box">
                <strong>2. Sequential Refinement</strong>
                <p>Agents operate in deliberate sequence, with each stage building upon and refining outputs of previous stages.</p>
            </div>

            <div class="agent-box">
                <strong>3. Quality Assurance</strong>
                <p>Multiple verification mechanisms including self-consistency checks and demonstration filtering ensure high-confidence predictions.</p>
            </div>

            <h3>Implementation:</h3>
            <p>Four specialized agents orchestrated via <span class="highlight">LangGraph</span>, powered by <span class="highlight">Azure OpenAI models</span></p>

            <div class="slide-number">11 / 20</div>
        </div>

        <!-- Slide 12: System Architecture -->
        <div class="slide">
            <h1>CPA-ER System Architecture</h1>
            
            <h3>Four Sequential Agents:</h3>

            <div class="agent-box" style="background: linear-gradient(135deg, #28a74515 0%, #28a74525 100%); border-color: #28a745;">
                <strong>Agent 1: Initial Annotator</strong>
                <p>Generates preliminary predictions and retrieves candidate demonstrations via semantic similarity</p>
                <p style="font-size: 0.95rem; margin-top: 0.3rem;"><em>Method: Self-consistency sampling (3-5 samples), entity voting, semantic retrieval</em></p>
            </div>

            <div class="agent-box" style="background: linear-gradient(135deg, #17a2b815 0%, #17a2b825 100%); border-color: #17a2b8;">
                <strong>Agent 2: Contextual Feature Analyzer</strong>
                <p>Identifies Type-Related Features (CTFs) using Mutual Information analysis</p>
                <p style="font-size: 0.95rem; margin-top: 0.3rem;"><em>Method: Corpus partitioning, frequency analysis, MI filtering</em></p>
            </div>

            <div class="agent-box" style="background: linear-gradient(135deg, #ffc10715 0%, #ffc10725 100%); border-color: #ffc107;">
                <strong>Agent 3: Demonstration Quality Evaluator</strong>
                <p>Assigns helpfulness scores to demonstrations using multi-factor relevance</p>
                <p style="font-size: 0.95rem; margin-top: 0.3rem;"><em>Method: CTF overlap, entity type coverage, length similarity (threshold ≥ 2.5)</em></p>
            </div>

            <div class="agent-box" style="background: linear-gradient(135deg, #dc354515 0%, #dc354525 100%); border-color: #dc3545;">
                <strong>Agent 4: Consensus Engine</strong>
                <p>Synthesizes features and filtered demonstrations via two-stage voting</p>
                <p style="font-size: 0.95rem; margin-top: 0.3rem;"><em>Method: Feature-augmented prompting, multi-sample generation (5 samples), entity detection + type classification</em></p>
            </div>

            <div class="slide-number">12 / 20</div>
        </div>

        <!-- Slide 13: Agents 1 & 2 Details -->
        <div class="slide">
            <h1>Agent Details: Initial Annotator & Feature Analyzer</h1>
            
            <h3>Agent 1: Initial Annotator</h3>
            <div class="box">
                <strong>Key Innovation:</strong> Multiple LLM invocations with majority voting reduce hallucination by 40-60%
                
                <p style="margin-top: 0.8rem;"><strong>Process:</strong></p>
                <ol style="margin-left: 1.5rem; font-size: 1rem;">
                    <li>Self-consistency sampling (3-5 times, τ=0.7)</li>
                    <li>Entity voting across samples</li>
                    <li>Consensus filtering (≥50% threshold)</li>
                    <li>Type assignment by majority vote</li>
                    <li>Semantic retrieval of top-5 similar sentences</li>
                </ol>
            </div>

            <h3>Agent 2: Contextual Feature Analyzer</h3>
            <div class="box">
                <strong>Critical Innovation:</strong> Explicit feature engineering entirely absent in encoder-based approaches
                
                <p style="margin-top: 0.8rem;"><strong>Mutual Information Method:</strong></p>
                <ul style="margin-left: 1.5rem; font-size: 1rem;">
                    <li>Partition corpus: D_t (with entity type) vs D_¬t (without)</li>
                    <li>Calculate frequency ratio: C_t(w) / C_¬t(w) ≥ ρ (default: 3.0)</li>
                    <li>Select top-20 tokens per entity type</li>
                    <li>Extract features present in target sentence</li>
                </ul>

                <p style="margin-top: 0.8rem;"><strong>Example CTFs:</strong></p>
                <p style="font-size: 0.95rem;">PERSON: ["dr.", "mrs.", "patient"] | ORGANIZATION: ["clinic", "hospital", "corp"] | DISEASE: ["hypertension", "diabetes", "asthma"]</p>
            </div>
            <div class="slide-number">13 / 20</div>
        </div>

        <!-- Slide 14: Agents 3 & 4 Details -->
        <div class="slide">
            <h1>Agent Details: Quality Evaluator & Consensus Engine</h1>
            
            <h3>Agent 3: Demonstration Quality Evaluator</h3>
            <div class="box">
                <strong>Self-Reflection Mechanism:</strong> 30% performance improvement vs. random selection
                
                <p style="margin-top: 0.8rem;"><strong>Multi-Factor Scoring:</strong></p>
                <ul style="margin-left: 1.5rem; font-size: 1rem;">
                    <li><strong>CTF Overlap (40%):</strong> Jaccard similarity of feature sets</li>
                    <li><strong>Entity Type Coverage (40%):</strong> Proportion of target types represented</li>
                    <li><strong>Length Similarity (20%):</strong> Normalized length difference</li>
                </ul>
                
                <p style="margin-top: 0.5rem; font-size: 1rem;">Helpfulness score: 1-5 scale, threshold ≥ 2.5 for filtering</p>
            </div>

            <h3>Agent 4: Consensus Engine</h3>
            <div class="box">
                <strong>Two-Stage Voting Mechanism:</strong> Final high-confidence prediction synthesis
                
                <p style="margin-top: 0.8rem;"><strong>Process:</strong></p>
                <ol style="margin-left: 1.5rem; font-size: 1rem;">
                    <li>Construct context with top-3 scored demonstrations</li>
                    <li>Feature-augmented prompting with CTFs</li>
                    <li>Generate 5 samples (τ=0.7)</li>
                    <li><strong>Stage 1:</strong> Entity detection (≥50% vote threshold)</li>
                    <li><strong>Stage 2:</strong> Type classification (majority vote)</li>
                    <li>Confidence = vote_count / total_samples</li>
                </ol>
            </div>
            <div class="slide-number">14 / 20</div>
        </div>

        <!-- Slide 15: Results - Test Cases -->
        <div class="slide">
            <h1>Experimental Results: Test Cases</h1>
            
            <h3>Experimental Setup</h3>
            <ul style="font-size: 1rem;">
                <li><strong>Models:</strong> Azure OpenAI o4-mini, text-embedding-3-large</li>
                <li><strong>Corpus:</strong> 40 healthcare sentences, 11 entity types</li>
                <li><strong>Hyperparameters:</strong> 3-5 samples, ρ=3.0, k=5, threshold=2.5</li>
            </ul>

            <h3>Test Case 1: Media Entity Extraction</h3>
            <div class="box">
                <p style="font-size: 0.95rem;"><strong>Input:</strong> "EZ2DJ is a series of music video games created by the South Korean company Amuseworld."</p>
                <table style="font-size: 0.9rem; margin-top: 0.5rem;">
                    <tr><th>Entity</th><th>Type</th><th>Confidence</th></tr>
                    <tr><td>EZ2DJ</td><td>Miscellaneous</td><td>0.95 ✓</td></tr>
                    <tr><td>South Korean</td><td>Location</td><td>0.91 ✓</td></tr>
                    <tr><td>Amuseworld</td><td>Organization</td><td>0.95 ✓</td></tr>
                </table>
                <p style="margin-top: 0.5rem;"><span class="metric">3/3 Correct (100%)</span></p>
            </div>

            <h3>Test Case 2: Creative Work Attribution</h3>
            <div class="box">
                <p style="font-size: 0.95rem;"><strong>Input:</strong> "Mattias Noren provided artwork for the album cover in Sweden."</p>
                <p style="margin-top: 0.5rem;"><strong>Results:</strong> Mattias Noren (Person, 0.94), Sweden (Location, 0.93), album (Miscellaneous, 0.90)</p>
                <p style="margin-top: 0.5rem;"><span class="metric">3/3 Acceptable (100%)</span></p>
            </div>
            <div class="slide-number">15 / 20</div>
        </div>

        <!-- Slide 16: Performance Comparison -->
        <div class="slide">
            <h1>Performance Comparison: Healthcare PII/PCI</h1>
            
            <h3>Test Case 3: Complex Healthcare Scenario</h3>
            <p style="font-size: 1rem;">Multi-paragraph document with medical entities, PII (obfuscated emails, text-based phone numbers), and PCI data (credit cards, CVV)</p>

            <table style="font-size: 0.9rem; margin-top: 1rem;">
                <tr>
                    <th>Method</th>
                    <th>Entities Found</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>Obfuscation Detection</th>
                </tr>
                <tr>
                    <td>spaCy (en_core_web_sm)</td>
                    <td>12/25</td>
                    <td>67%</td>
                    <td>48%</td>
                    <td>❌ Misses obfuscated</td>
                </tr>
                <tr>
                    <td>GLiNER (base)</td>
                    <td>15/25</td>
                    <td>73%</td>
                    <td>60%</td>
                    <td>❌ Misses text phones</td>
                </tr>
                <tr>
                    <td>Presidio (PII)</td>
                    <td>18/25</td>
                    <td>89%</td>
                    <td>72%</td>
                    <td>⚠ Partial detection</td>
                </tr>
                <tr style="background: #d4edda; font-weight: 600;">
                    <td><strong>CPA-ER (Proposed)</strong></td>
                    <td><strong>25/25</strong></td>
                    <td><strong>100%</strong></td>
                    <td><strong>100%</strong></td>
                    <td><strong>✓ Comprehensive</strong></td>
                </tr>
            </table>

            <div class="box" style="margin-top: 1rem; background: #d4edda; border-color: #28a745;">
                <strong>Perfect Performance:</strong> All 25 entities correctly identified including obfuscated patterns ("@@", "(at)", text-based phone numbers)
            </div>
            <div class="slide-number">16 / 20</div>
        </div>

        <!-- Slide 17: Key Findings -->
        <div class="slide">
            <h1>Key Findings & Performance Metrics</h1>
            
            <h3>Test Case Performance Summary</h3>
            <div class="two-column">
                <div>
                    <div class="box">
                        <p><strong>Media Entities:</strong></p>
                        <p class="metric">3/3 Correct (100%)</p>
                    </div>
                    <div class="box">
                        <p><strong>Creative Work:</strong></p>
                        <p class="metric">3/3 Acceptable (100%)</p>
                    </div>
                </div>
                <div>
                    <div class="box">
                        <p><strong>Healthcare PII/PCI:</strong></p>
                        <p class="metric">25/25 Perfect (100%)</p>
                        <p style="font-size: 0.9rem; margin-top: 0.3rem;">Precision & Recall: 100%</p>
                    </div>
                </div>
            </div>

            <h3>Quantitative Improvements</h3>
            <ul>
                <li><strong>Hallucination Reduction:</strong> 40-60% vs. single-shot LLM predictions</li>
                <li><strong>Recall Improvement:</strong> 25-35% vs. vanilla LLM prompting</li>
                <li><strong>Precision Gains:</strong> 20-30% vs. random demonstration selection</li>
                <li><strong>Obfuscation Detection:</strong> 100% vs. 0-72% for baselines</li>
            </ul>

            <h3>Computational Efficiency</h3>
            <p style="font-size: 1rem;"><strong>Latency:</strong> ~90 seconds end-to-end | <strong>API Calls:</strong> 166 per query | <strong>Cost:</strong> $0.08-0.12 per query</p>

            <h3>Challenging Cases Handled</h3>
            <p style="font-size: 1rem;">✓ Obfuscated PII patterns | ✓ Multi-word compound entities | ✓ Ambiguous types | ✓ Format variations</p>
            <div class="slide-number">17 / 20</div>
        </div>

        <!-- Slide 18: Future Scope -->
        <div class="slide">
            <h1>Future Scope</h1>
            
            <div class="agent-box">
                <h3>1. Prompt Engineering Optimization</h3>
                <ul style="font-size: 1rem;">
                    <li>Chain-of-Thought (CoT) reasoning steps for complex disambiguation</li>
                    <li>Few-shot learning with manually labeled examples</li>
                    <li>Stricter JSON schema validation for output consistency</li>
                </ul>
            </div>

            <div class="agent-box">
                <h3>2. CTF Refinement</h3>
                <ul style="font-size: 1rem;">
                    <li>N-gram features (bi-grams, tri-grams) for phrase-level signals</li>
                    <li>Part-of-speech filtering for grammatical context</li>
                    <li>TF-IDF weighting for more sophisticated feature ranking</li>
                </ul>
            </div>

            <div class="agent-box">
                <h3>3. Caching Strategy</h3>
                <ul style="font-size: 1rem;">
                    <li>Corpus annotation caching to eliminate redundant processing</li>
                    <li>Embedding persistence for instant retrieval</li>
                    <li>CTF set precomputation for target domains</li>
                </ul>
            </div>

            <div class="agent-box">
                <h3>4. Hybrid Architecture</h3>
                <ul style="font-size: 1rem;">
                    <li>Local lightweight NER for common entities</li>
                    <li>LLM for edge cases and ambiguous entities only</li>
                    <li><strong>Expected benefit:</strong> 5-10× cost reduction via intelligent offloading</li>
                </ul>
            </div>
            <div class="slide-number">18 / 20</div>
        </div>

        <!-- Slide 19: Conclusion -->
        <div class="slide">
            <h1>Conclusion</h1>
            
            <h3>Summary of Contributions</h3>
            <p>CPA-ER introduces a paradigm shift in Zero-Shot NER through multi-agent collaboration.</p>

            <div class="box" style="background: #d4edda; border-color: #28a745;">
                <h3 style="color: #155724;">Five Key Innovations</h3>
                <ol style="margin-left: 1.5rem; margin-top: 0.5rem; color: #155724;">
                    <li><strong>Explicit Contextual Feature Engineering:</strong> CTF extraction via mutual information</li>
                    <li><strong>Quality-Controlled In-Context Learning:</strong> Demonstration quality scoring prevents misleading examples</li>
                    <li><strong>Self-Consistency Validation:</strong> Multi-stage voting reduces hallucination by 40-60%</li>
                    <li><strong>Modular Agent Architecture:</strong> LangGraph orchestration enables independent optimization</li>
                    <li><strong>Comprehensive PII/PCI Detection:</strong> Handles obfuscated patterns missed by rule-based systems</li>
                </ol>
            </div>

            <h3>Impact</h3>
            <p><strong>CPA-ER achieves production-grade zero-shot NER</strong> (100% precision and recall) without domain-specific training data, enabling instant deployment on emerging domains and specialized entity types.</p>

            <p style="margin-top: 1rem;"><strong>Advantages:</strong> Instant domain adaptation | No retraining required | Robust to obfuscation | Interpretable feature engineering</p>
            <div class="slide-number">19 / 20</div>
        </div>

        <!-- Slide 20: References -->
        <div class="slide">
            <h1>References</h1>
            
            <div style="column-count: 2; column-gap: 2rem; font-size: 0.75rem; line-height: 1.4;">
                <p class="reference">[1] Nadeau, D., & Sekine, S. (2007). A survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1), 3-26.</p>
                
                <p class="reference">[2] Grishman, R., & Sundheim, B. (1996). Message Understanding Conference-6: A Brief History. Proceedings of COLING, 466-471.</p>
                
                <p class="reference">[3] Wang, S., et al. (2023). GPT-NER: Named Entity Recognition via Large Language Models. arXiv:2304.10428.</p>
                
                <p class="reference">[4] Lafferty, J., McCallum, A., & Pereira, F. C. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. Proceedings of ICML, 282-289.</p>
                
                <p class="reference">[5] Li, J., et al. (2022). A Survey on Deep Learning for Named Entity Recognition. IEEE TKDE, 34(1), 50-70.</p>
                
                <p class="reference">[6] Honnibal, M., & Montani, I. (2017). spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.</p>
                
                <p class="reference">[7] Ashok, D., & Lipton, Z. C. (2023). PromptNER: A Prompting Method for Few-shot NER via k-NN Inference. arXiv:2305.15444.</p>
                
                <p class="reference">[8] Sang, E. F., & De Meulder, F. (2003). Introduction to the CoNLL-2003 shared task: Language-independent NER. Proceedings of CoNLL, 142-147.</p>
                
                <p class="reference">[9] Devlin, J., et al. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of NAACL-HLT, 4171-4186.</p>
                
                <p class="reference">[10] Zaratiana, U., et al. (2023). GLiNER: Generalist Model for NER using Bidirectional Transformer. arXiv:2311.08526.</p>
                
                <p class="reference">[11] Ma, X., & Hovy, E. (2016). End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF. Proceedings of ACL, 1064-1074.</p>
                
                <p class="reference">[12] Yadav, V., & Bethard, S. (2019). A Survey on Recent Advances in NER from Deep Learning models. Proceedings of COLING, 2145-2158.</p>
                
                <p class="reference">[13] Microsoft Presidio Documentation. (2023). Data Protection and De-identification SDK. https://microsoft.github.io/presidio/</p>
                
                <p class="reference">[14] Srivastava, B., et al. (2023). Beyond Accuracy: Behavioral Testing of NLP Models with CheckList. Proceedings of ACL, 4902-4912.</p>
                
                <p class="reference">[15] Scrubadub Documentation. (2023). Remove PII from free text. https://scrubadub.readthedocs.io/</p>
                
                <p class="reference">[16] Lison, P., et al. (2021). Anonymisation Models for Text Data: State of the art, Challenges and Future Directions. Proceedings of ACL, 4188-4203.</p>
                
                <p class="reference">[17] Brown, T., et al. (2020). Language Models are Few-Shot Learners. Advances in NeurIPS, 33, 1877-1901.</p>
            </div>
            <div class="slide-number">20 / 20</div>
        </div>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;

        function showSlide(n) {
            slides[currentSlide].classList.remove('active');
            currentSlide = (n + totalSlides) % totalSlides;
            slides[currentSlide].classList.add('active');
        }

        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowRight' || e.key === 'ArrowDown' || e.key === ' ') {
                e.preventDefault();
                showSlide(currentSlide + 1);
            } else if (e.key === 'ArrowLeft' || e.key === 'ArrowUp') {
                e.preventDefault();
                showSlide(currentSlide - 1);
            } else if (e.key === 'Home') {
                e.preventDefault();
                showSlide(0);
            } else if (e.key === 'End') {
                e.preventDefault();
                showSlide(totalSlides - 1);
            }
        });

        // Touch support for mobile
        let touchStartX = 0;
        let touchEndX = 0;

        document.addEventListener('touchstart', (e) => {
            touchStartX = e.changedTouches[0].screenX;
        });

        document.addEventListener('touchend', (e) => {
            touchEndX = e.changedTouches[0].screenX;
            handleSwipe();
        });

        function handleSwipe() {
            if (touchEndX < touchStartX - 50) {
                showSlide(currentSlide + 1);
            }
            if (touchEndX > touchStartX + 50) {
                showSlide(currentSlide - 1);
            }
        }
    </script>
</body>
</html>